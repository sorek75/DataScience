{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/san_fran_crime.csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Import the data from the .csv file\n",
    "dataset = pandas.read_csv('san_fran_crime.csv', delimiter=\"\\t\")\n",
    "\n",
    "# Remember to one-hot encode our crime and PdDistrict variables \n",
    "categorical_features = [\"Category\", \"PdDistrict\"]\n",
    "dataset = pandas.get_dummies(dataset, columns=categorical_features, drop_first=False)\n",
    "\n",
    "# Split the dataset in an 90/10 train/test ratio. \n",
    "# Recall that our dataset is very large so we can afford to do this\n",
    "# with only 10% entering the test set\n",
    "train, test = train_test_split(dataset, test_size=0.1, random_state=2, shuffle=True)\n",
    "\n",
    "# Let's have a look at the data and the relationship we are going to model\n",
    "print(dataset.head())\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Make a utility method that we can re-use throughout this exercise\n",
    "# To easily fit and test out model\n",
    "\n",
    "features = [c for c in dataset.columns if c != \"Resolution\"]\n",
    "\n",
    "def fit_and_test_model(model):\n",
    "    '''\n",
    "    Trains a model and tests it against both train and test sets\n",
    "    '''  \n",
    "    global features\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train[features], train.Resolution)\n",
    "\n",
    "    # Assess its performance\n",
    "    # -- Train\n",
    "    predictions = model.predict(train[features])\n",
    "    train_accuracy = balanced_accuracy_score(train.Resolution, predictions)\n",
    "\n",
    "    # -- Test\n",
    "    predictions = model.predict(test[features])\n",
    "    test_accuracy = balanced_accuracy_score(test.Resolution, predictions)\n",
    "\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "# re-fit our last decision tree to print out its performance\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=10) \n",
    "\n",
    "dt_train_accuracy, dt_test_accuracy = fit_and_test_model(model)\n",
    "\n",
    "print(\"Decision Tree Performance:\")\n",
    "print(\"Train accuracy\", dt_train_accuracy)\n",
    "print(\"Test accuracy\", dt_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest model with two trees\n",
    "random_forest = RandomForestClassifier( n_estimators=2,\n",
    "                                        random_state=2,\n",
    "                                        verbose=False)\n",
    "\n",
    "# Train and test the model\n",
    "train_accuracy, test_accuracy = fit_and_test_model(random_forest)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing\n",
    "\n",
    "# n_estimators states how many trees to put in the model\n",
    "# We will make one model for every entry in this list\n",
    "# and see how well each model performs \n",
    "n_estimators = [2, 5, 10, 20, 50]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    print(\"Preparing a model with\", n_estimator, \"trees...\")\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimator, \n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D(dict(Train=train_accuracies, Test=test_accuracies), \n",
    "                    n_estimators,\n",
    "                    label_x=\"Numer of trees (n_estimators)\",\n",
    "                    label_y=\"Accuracy\",\n",
    "                    title=\"Performance X number of trees\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink the training set temporarily to explore this\n",
    "# setting with a more normal sample size\n",
    "full_trainset = train\n",
    "train = full_trainset[:1000] # limit to 1000 samples\n",
    "\n",
    "min_samples_split = [2, 10, 20, 50, 100, 500]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for min_samples in min_samples_split:\n",
    "    print(\"Preparing a model with min_samples_split = \", min_samples)\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=20,\n",
    "                                min_samples_split=min_samples,\n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D(dict(Train=train_accuracies, Test=test_accuracies), \n",
    "                    min_samples_split,\n",
    "                    label_x=\"Minimum samples split (min_samples_split)\",\n",
    "                    label_y=\"Accuracy\",\n",
    "                    title=\"Performance\", show=True)\n",
    "\n",
    "# Rol back the trainset to the full set\n",
    "train = full_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink the training set temporarily to explore this\n",
    "# setting with a more normal sample size\n",
    "full_trainset = train\n",
    "train = full_trainset[:500] # limit to 500 samples\n",
    "\n",
    "max_depths = [2, 4, 6, 8, 10, 15, 20, 50, 100]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    print(\"Preparing a model with max_depth = \", max_depth)\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=20,\n",
    "                                max_depth=max_depth,\n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D(dict(Train=train_accuracies, Test=test_accuracies),\n",
    "                    max_depths,\n",
    "                    label_x=\"Maximum depth (max_depths)\",\n",
    "                    label_y=\"Accuracy\",\n",
    "                    title=\"Performance\", show=True)\n",
    "\n",
    "# Rol back the trainset to the full set\n",
    "train = full_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model \n",
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                            max_depth=128,\n",
    "                            max_features=25,\n",
    "                            min_samples_split=2,\n",
    "                            random_state=2, \n",
    "                            verbose=False)\n",
    "\n",
    "# Train and test the result\n",
    "print(\"Training model. This may take 1 - 2 minutes\")\n",
    "train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "# Print out results, compared to the decision tree\n",
    "data = {\"Model\": [\"Decision tree\",\"Final random forest\"],\n",
    "        \"Train sensitivity\": [dt_train_accuracy, train_accuracy],\n",
    "        \"Test sensitivity\": [dt_test_accuracy, test_accuracy]\n",
    "        }\n",
    "\n",
    "pandas.DataFrame(data, columns = [\"Model\", \"Train sensitivity\", \"Test sensitivity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
