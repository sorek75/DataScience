{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"surface_hoar\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"fresh_thickness\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"weak_layers\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"no_visitors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import a function that splits datasets according to a given ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict to get a probability\n",
    "\n",
    "# get first 3 samples from dataset\n",
    "samples = test[\"weak_layers\"][:4]\n",
    "\n",
    "# use the model to get predictions as possibilities\n",
    "estimated_probabilities = model.predict(samples)\n",
    "\n",
    "# Print results for each sample\n",
    "for sample, pred in zip(samples,estimated_probabilities):\n",
    "    print(f\"A weak_layer with value {sample} yields a {pred * 100:.2f}% chance of an avalanche.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "# Show a graph of the result\n",
    "predict = lambda x: model.predict(pandas.DataFrame({\"weak_layers\": x}))\n",
    "\n",
    "graphing.line_2D([(\"Model\", predict)],\n",
    "                 x_range=[-20,40],\n",
    "                 label_x=\"weak_layers\", \n",
    "                 label_y=\"estimated probability of an avalanche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum number of weak layers:\", min(train.weak_layers))\n",
    "print(\"Maximum number of weak layers:\", max(train.weak_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get actual rates of avalanches at 0 years\n",
    "avalanche_outcomes_for_0_layers = train[train.weak_layers == 0].avalanche\n",
    "print(\"Average rate of avalanches for 0 weak layers of snow\", np.average(avalanche_outcomes_for_0_layers))\n",
    "\n",
    "# Get actual rates of avalanches at 10 years\n",
    "avalanche_outcomes_for_10_layers = train[train.weak_layers == 10].avalanche\n",
    "print(\"Average rate of avalanches for 10 weak layers of snow\", np.average(avalanche_outcomes_for_10_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to get an absolute value\n",
    "threshold = 0.5\n",
    "\n",
    "# Add classification to the samples we used before\n",
    "for sample, pred in list(zip(samples,estimated_probabilities)):\n",
    "    print(f\"A weak_layer with value {sample} yields a chance of {pred * 100:.2f}% of an avalanche. Classification = {pred > threshold}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the mdel predictions using the threshold\n",
    "predictions = model.predict(test) > threshold\n",
    "\n",
    "# Compare the predictions to the actual outcomes in the dataset\n",
    "accuracy = np.average(predictions == test.avalanche)\n",
    "\n",
    "# Print the evaluation\n",
    "print(f\"The model correctly predicted outcomes {accuracy * 100:.2f}% of time.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
