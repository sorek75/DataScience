{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/san_fran_crime.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('san_fran_crime.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data and the relationship we are going to model\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "import numpy as np\n",
    "\n",
    "# Crime category\n",
    "graphing.multiple_histogram(dataset, label_x='Category', label_group=\"Resolution\", histfunc='sum', show=True)\n",
    "\n",
    "# District\n",
    "graphing.multiple_histogram(dataset, label_group=\"Resolution\", label_x=\"PdDistrict\", show=True)\n",
    "\n",
    "# Map of crimes\n",
    "graphing.scatter_2D(dataset, label_x=\"X\", label_y=\"Y\", label_colour=\"Resolution\", title=\"GPS Coordinates\", size_multiplier=0.8, show=True)\n",
    "\n",
    "# Day of the week\n",
    "graphing.multiple_histogram(dataset, label_group=\"Resolution\", label_x=\"DayOfWeek\", show=True)\n",
    "\n",
    "# day of the year\n",
    "# For graphing we simplify this to week or the graph becomes overwhelmed with bars\n",
    "dataset[\"week_of_year\"] = np.round(dataset.day_of_year / 7.0)\n",
    "graphing.multiple_histogram(dataset, \n",
    "                    label_x='week_of_year',\n",
    "                    label_group='Resolution',\n",
    "                    histfunc='sum', show=True)\n",
    "del dataset[\"week_of_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "dataset = pandas.get_dummies(dataset, columns=[\"Category\", \"PdDistrict\"], drop_first=False)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 90/10 train/test ratio. \n",
    "# We can afford to do this here because our dataset is very very large\n",
    "# Normally we would choose a more even ratio\n",
    "train, test = train_test_split(dataset, test_size=0.1, random_state=2, shuffle=True)\n",
    "\n",
    "print(\"Data shape:\")\n",
    "print(\"train\", train.shape)\n",
    "print(\"test\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Make a utility method that we can re-use throughout this exercise\n",
    "# To easily fit and test out model\n",
    "\n",
    "features = [c for c in dataset.columns if c != \"Resolution\"]\n",
    "\n",
    "\n",
    "def fit_and_test_model(model):\n",
    "    '''\n",
    "    Trains a model and tests it against both train and test sets\n",
    "    '''  \n",
    "    global features\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train[features], train.Resolution)\n",
    "\n",
    "    # Assess its performance\n",
    "    # -- Train\n",
    "    predictions = model.predict(train[features])\n",
    "    train_accuracy = balanced_accuracy_score(train.Resolution, predictions)\n",
    "\n",
    "    # -- Test\n",
    "    predictions = model.predict(test[features])\n",
    "    test_accuracy = balanced_accuracy_score(test.Resolution, predictions)\n",
    "\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "# fit a simple tree using only three levels\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=2, max_depth=3) \n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "\n",
    "print(\"Model trained!\")\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plot = plt.subplots(figsize = (4,4), dpi=300)[0]\n",
    "plot = plot_tree(model,\n",
    "                fontsize=3,\n",
    "                feature_names = features, \n",
    "                class_names = ['0','1'], # class_names in ascending numerical order \n",
    "                label=\"root\",\n",
    "                impurity=False,\n",
    "                filled=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a very deep tree\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=100)\n",
    "\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily shrink the training set to something\n",
    "# more realistic\n",
    "full_training_set = train\n",
    "train = train[:100]\n",
    "\n",
    "# fit the same tree as before\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=100)\n",
    "\n",
    "# Assess on the same test set as before\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n",
    "\n",
    "# Roll the training set back to the full set\n",
    "train = full_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily shrink the training set to 10000\n",
    "# for this exercise to see how pruning is important\n",
    "# even with moderately large datasets\n",
    "full_training_set = train\n",
    "train = train[:10000]\n",
    "\n",
    "\n",
    "# Loop through the values below and build a model\n",
    "# each time, setting the maximum depth to that value \n",
    "max_depth_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,15, 20, 50, 100]\n",
    "accuracy_trainset = []\n",
    "accuracy_testset = []\n",
    "for depth in max_depth_range:\n",
    "    # Create and fit the model\n",
    "    prune_model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=depth)\n",
    "\n",
    "    # Calculate and record its sensitivity\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(prune_model)\n",
    "    accuracy_trainset.append(train_accuracy)\n",
    "    accuracy_testset.append(test_accuracy)\n",
    "\n",
    "# Plot the sensitivity as a function of depth  \n",
    "pruned_plot = pandas.DataFrame(dict(max_depth=max_depth_range, accuracy=accuracy_trainset))\n",
    "\n",
    "fig = graphing.line_2D(dict(train=accuracy_trainset, test=accuracy_testset), x_range=max_depth_range, show=True)\n",
    "\n",
    "# Roll the training set back to the full thing\n",
    "train = full_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily shrink the training set to 10000\n",
    "# for this exercise to see how pruning is important\n",
    "# even with moderately large datasets\n",
    "full_training_set = train\n",
    "train = train[:10000]\n",
    "\n",
    "\n",
    "# Not-pruned\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1)\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Unpruned Train accuracy\", train_accuracy)\n",
    "print(\"Unpruned Test accuracy\", test_accuracy)\n",
    "\n",
    "\n",
    "# re-fit our final tree to print out its performance\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=10)\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n",
    "\n",
    "# Roll the training set back to the full thing\n",
    "train = full_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
